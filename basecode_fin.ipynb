{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus ì˜ˆì‹œ:\n",
      "   doc_id                                               text\n",
      "0       0  The U.S. Social Security Administration (SSA),...\n",
      "1       1  Arnold Alois Schwarzenegger (/ËˆÊƒwÉ”ËrtsÉ™nËŒÉ›É¡É™r/...\n",
      "2       2  In 2006, the Sister City Program of the City o...\n",
      "3       3  By 1840, the Market Hall and Sheds, where fres...\n",
      "4       4  Some commentators have defined reverse discrim...\n",
      "\n",
      "QA ìŒ ì˜ˆì‹œ:\n",
      "                                            question  \\\n",
      "0  To whom did the Virgin Mary allegedly appear i...   \n",
      "1  What is in front of the Notre Dame Main Building?   \n",
      "2  The Basilica of the Sacred heart at Notre Dame...   \n",
      "3                  What is the Grotto at Notre Dame?   \n",
      "4  What sits on top of the Main Building at Notre...   \n",
      "\n",
      "                                    answer  doc_id  \\\n",
      "0               Saint Bernadette Soubirous   14556   \n",
      "1                a copper statue of Christ   14556   \n",
      "2                        the Main Building   14556   \n",
      "3  a Marian place of prayer and reflection   14556   \n",
      "4       a golden statue of the Virgin Mary   14556   \n",
      "\n",
      "                                             context  \n",
      "0  Architecturally, the school has a Catholic cha...  \n",
      "1  Architecturally, the school has a Catholic cha...  \n",
      "2  Architecturally, the school has a Catholic cha...  \n",
      "3  Architecturally, the school has a Catholic cha...  \n",
      "4  Architecturally, the school has a Catholic cha...  \n"
     ]
    }
   ],
   "source": [
    "# 1. SQuAD ë°ì´í„° ë¡œë“œ (í›ˆë ¨ ì„¸íŠ¸ ê¸°ì¤€, validationë„ ê°€ëŠ¥)\n",
    "dataset = load_dataset(\"squad\", split=\"train\")\n",
    "\n",
    "# 2. ê³ ìœ í•œ context ë¬¸ì„œ ì§‘í•© ìƒì„± (retrieval corpusë¡œ ì‚¬ìš©)\n",
    "unique_contexts = list(set(dataset[\"context\"]))\n",
    "corpus_df = pd.DataFrame({\"doc_id\": list(range(len(unique_contexts))), \"text\": unique_contexts})\n",
    "\n",
    "# 3. QA ìŒ êµ¬ì„± (ì§ˆë¬¸, ì •ë‹µ, í•´ë‹¹ ë¬¸ì„œ)\n",
    "qa_data = []\n",
    "context_to_id = {context: idx for idx, context in enumerate(unique_contexts)}\n",
    "\n",
    "for item in dataset:\n",
    "    question = item[\"question\"]\n",
    "    answer = item[\"answers\"][\"text\"][0] if item[\"answers\"][\"text\"] else \"\"\n",
    "    context = item[\"context\"]\n",
    "    doc_id = context_to_id[context]\n",
    "    qa_data.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"doc_id\": doc_id,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "qa_pairs = pd.DataFrame(qa_data)\n",
    "\n",
    "# 4. ê²°ê³¼ ë¯¸ë¦¬ ë³´ê¸°\n",
    "print(\"Corpus ì˜ˆì‹œ:\")\n",
    "print(corpus_df.head())\n",
    "\n",
    "print(\"\\nQA ìŒ ì˜ˆì‹œ:\")\n",
    "print(qa_pairs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ:\n",
      "- squad_rag_corpus.json\n",
      "- squad_rag_qa_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# 1. corpus ì €ì¥ (Retrieval ë¬¸ì„œë“¤)\n",
    "corpus_records = corpus_df.to_dict(orient=\"records\")\n",
    "with open(\"dataset/squad_rag_corpus2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(corpus_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 2. QA ìŒ ì €ì¥ (ì§ˆë¬¸-ì •ë‹µ-ë¬¸ì„œ ë§¤í•‘)\n",
    "qa_records = qa_pairs.to_dict(orient=\"records\")\n",
    "with open(\"dataset/squad_rag_qa_pairs2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(\"- squad_rag_corpus.json\")\n",
    "print(\"- squad_rag_qa_pairs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save embedded vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aix7101/anaconda3/envs/j_project/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "/home/aix7101/anaconda3/envs/j_project/lib/python3.9/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Load DPR model and tokenizer (use multi-qa)\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRQuestionEncoder(\n",
       "  (question_encoder): DPREncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_encoder.eval()\n",
    "q_encoder.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ctx_encoder.to(device)\n",
    "q_encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë¬¸ì„œ ì„ë² ë”© ìƒì„±\n",
    "ctx_embeddings = []\n",
    "for doc in tqdm(corpus_df[\"text\"], desc=\"Encoding contexts\"):\n",
    "    inputs = ctx_tokenizer(doc, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # ì…ë ¥ë„ GPUë¡œ ì´ë™\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = ctx_encoder(**inputs).pooler_output[0].cpu().numpy()  # ê²°ê³¼ë§Œ ë‹¤ì‹œ CPUë¡œ\n",
    "    ctx_embeddings.append(emb)\n",
    "\n",
    "ctx_embeddings = np.stack(ctx_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87599/87599 [14:09<00:00, 103.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. ì§ˆë¬¸ ì„ë² ë”© ìƒì„±\n",
    "q_embeddings = []\n",
    "for q in tqdm(qa_pairs[\"question\"], desc=\"Encoding questions\"):\n",
    "    inputs = q_tokenizer(q, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # âœ… ì…ë ¥ë„ GPUë¡œ ì´ë™\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = q_encoder(**inputs).pooler_output[0].cpu().numpy()  # âœ… ê²°ê³¼ë§Œ ë‹¤ì‹œ CPUë¡œ ì´ë™\n",
    "    q_embeddings.append(emb)\n",
    "\n",
    "q_embeddings = np.stack(q_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Context embeddings saved to: /mnt/aix7101/jeong/aix_project/dpr_ctx_embeddings2.npy\n",
      "âœ… Question embeddings saved to: /mnt/aix7101/jeong/aix_project/dpr_q_embeddings2.npy\n"
     ]
    }
   ],
   "source": [
    "# 4. ì €ì¥\n",
    "embedding_dir = \"/mnt/aix7101/jeong/aix_project\"\n",
    "if not os.path.exists(embedding_dir):\n",
    "    os.makedirs(embedding_dir)\n",
    "    print(f\"ğŸ“ Created directory: {embedding_dir}\")\n",
    "\n",
    "ctx_path = os.path.join(embedding_dir, \"dpr_ctx_embeddings2.npy\")\n",
    "q_path = os.path.join(embedding_dir, \"dpr_q_embeddings2.npy\")\n",
    "\n",
    "np.save(ctx_path, ctx_embeddings)\n",
    "np.save(q_path, q_embeddings)\n",
    "\n",
    "print(f\"âœ… Context embeddings saved to: {ctx_path}\")\n",
    "print(f\"âœ… Question embeddings saved to: {q_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize  # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
    "\n",
    "ctx_sentence_embeddings = []\n",
    "\n",
    "for doc in tqdm(corpus_df[\"text\"], desc=\"Encoding multi-sentence contexts\"):\n",
    "    # 1. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "    sentences = sent_tokenize(doc)\n",
    "    \n",
    "    doc_embeddings = []\n",
    "    for sent in sentences:\n",
    "        inputs = ctx_tokenizer(\n",
    "            sent,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128  # ë¬¸ì¥ ê¸°ì¤€ì´ë¼ ê¸¸ì´ ì¤„ì—¬ë„ OK\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = ctx_encoder(**inputs).pooler_output[0].cpu().numpy()\n",
    "        doc_embeddings.append(emb)\n",
    "    \n",
    "    # ë¬¸ì„œì— ì†í•œ ë¬¸ì¥ ë²¡í„°ë“¤ì„ í•˜ë‚˜ì˜ arrayë¡œ (num_sents_in_doc, dim)\n",
    "    doc_embeddings = np.stack(doc_embeddings)\n",
    "    ctx_sentence_embeddings.append(doc_embeddings)\n",
    "\n",
    "# âš ï¸ ë¬¸ì„œë§ˆë‹¤ ë¬¸ì¥ ìˆ˜ê°€ ë‹¬ë¼ paddingì´ í•„ìš”í•  ìˆ˜ ìˆìŒ\n",
    "# â†’ 3D arrayë¡œ ë§Œë“¤ê¸° ìœ„í•´ íŒ¨ë”© (optional)\n",
    "max_len = max(e.shape[0] for e in ctx_sentence_embeddings)\n",
    "dim = ctx_sentence_embeddings[0].shape[1]\n",
    "\n",
    "# zero-padding\n",
    "padded_embeddings = np.zeros((len(ctx_sentence_embeddings), max_len, dim))\n",
    "for i, emb in enumerate(ctx_sentence_embeddings):\n",
    "    padded_embeddings[i, :emb.shape[0], :] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ì €ì¥\n",
    "embedding_dir = \"/mnt/aix7101/jeong/aix_project\"\n",
    "if not os.path.exists(embedding_dir):\n",
    "    os.makedirs(embedding_dir)\n",
    "    print(f\"ğŸ“ Created directory: {embedding_dir}\")\n",
    "\n",
    "sentence_ctx_path = os.path.join(embedding_dir, \"dpr_m_ctx_embeddings2.npy\")\n",
    "\n",
    "np.save(sentence_ctx_path, ctx_sentence_embeddings)\n",
    "\n",
    "print(f\"âœ… Context Sentence embeddings saved to: {sentence_ctx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_bm25_recall(qa_pairs: pd.DataFrame, corpus_df: pd.DataFrame, k: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    BM25 ê¸°ë°˜ Recall@k ê³„ì‚° í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        qa_pairs (pd.DataFrame): ì§ˆë¬¸-ì •ë‹µ ìŒì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ (columns: ['question', 'answer', 'doc_id'])\n",
    "        corpus_df (pd.DataFrame): ë¬¸ì„œ ì§‘í•© (columns: ['doc_id', 'text'])\n",
    "        k (int): top-k ë¬¸ì„œ ì¤‘ ì •ë‹µì´ í¬í•¨ë˜ëŠ”ì§€ í‰ê°€í•  k ê°’\n",
    "        \n",
    "    Returns:\n",
    "        float: Recall@k\n",
    "    \"\"\"\n",
    "    # 1. í† í¬ë‚˜ì´ì¦ˆëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    tokenized_corpus = [doc.split() for doc in corpus_df[\"text\"]]\n",
    "    \n",
    "    # 2. BM25 ì¸ë±ìŠ¤ êµ¬ì„±\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    hit_count = 0\n",
    "\n",
    "    # 3. ê° ì§ˆë¬¸ì— ëŒ€í•´ BM25 top-k ë¬¸ì„œ ê²€ìƒ‰\n",
    "    for _, row in tqdm(qa_pairs.iterrows(), total=len(qa_pairs), desc=\"Evaluating BM25 Recall@K\"):\n",
    "        question = row[\"question\"]\n",
    "        gt_doc_id = row[\"doc_id\"]\n",
    "\n",
    "        tokenized_query = question.split()\n",
    "        scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "        # ìƒìœ„ kê°œì˜ ë¬¸ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "        topk_indices = np.argsort(scores)[::-1][:k]\n",
    "        topk_doc_ids = corpus_df.iloc[topk_indices][\"doc_id\"].tolist()\n",
    "\n",
    "        if gt_doc_id in topk_doc_ids:\n",
    "            hit_count += 1\n",
    "\n",
    "    recall_at_k = hit_count / len(qa_pairs)\n",
    "    print(f\"ğŸ“Œ BM25 Recall@{k}: {recall_at_k:.4f}\")\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BM25 Recall@K:  31%|â–ˆâ–ˆâ–ˆ       | 27077/87599 [17:38<47:09, 21.39it/s]  "
     ]
    }
   ],
   "source": [
    "recall_bm25 = compute_bm25_recall(qa_pairs, corpus_df, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpr_recall(qa_pairs, corpus_df, ctx_emb_path, q_emb_path, k=5):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ ì„ë² ë”© íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ top-k ë¬¸ì„œ ì¤‘ ì •ë‹µ ë¬¸ì„œê°€ í¬í•¨ë˜ëŠ” ë¹„ìœ¨(Recall@k)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        qa_pairs (pd.DataFrame): ì§ˆë¬¸-ì •ë‹µ ìŒì´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ (columns: ['question', 'answer', 'doc_id'])\n",
    "        corpus_df (pd.DataFrame): ë¬¸ì„œ ì§‘í•© (columns: ['doc_id', 'text'])\n",
    "        ctx_emb_path (str): ë¬¸ì„œ ì„ë² ë”©ì´ ì €ì¥ëœ .npy ê²½ë¡œ\n",
    "        q_emb_path (str): ì§ˆë¬¸ ì„ë² ë”©ì´ ì €ì¥ëœ .npy ê²½ë¡œ\n",
    "        k (int): top-k ë¬¸ì„œ ì¤‘ ì •ë‹µì´ í¬í•¨ë˜ëŠ”ì§€ í‰ê°€í•  k ê°’\n",
    "        \n",
    "    Returns:\n",
    "        float: Recall@k\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ì„ë² ë”© ë¡œë“œ\n",
    "    ctx_embeddings = np.load(ctx_emb_path)\n",
    "    q_embeddings = np.load(q_emb_path)\n",
    "\n",
    "    assert len(q_embeddings) == len(qa_pairs), \"â— ì§ˆë¬¸ ì„ë² ë”© ìˆ˜ì™€ QA ìŒ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    hit_count = 0\n",
    "\n",
    "    # 2. ê° ì§ˆë¬¸ì— ëŒ€í•´ ìœ ì‚¬í•œ top-k ë¬¸ì„œ ê²€ìƒ‰\n",
    "    for idx, row in tqdm(qa_pairs.iterrows(), total=len(qa_pairs), desc=\"Evaluating Recall@K\"):\n",
    "        gt_doc_id = row[\"doc_id\"]\n",
    "        q_emb = q_embeddings[idx]\n",
    "\n",
    "        # ë¬¸ì„œë“¤ê³¼ì˜ ìœ ì‚¬ë„ (cosine ìœ ì‚¬ë„ ëŒ€ì‹  dot-product ì‚¬ìš©)\n",
    "        scores = np.dot(ctx_embeddings, q_emb)\n",
    "\n",
    "        # top-k ì¸ë±ìŠ¤\n",
    "        topk_indices = np.argsort(scores)[::-1][:k]\n",
    "        topk_doc_ids = corpus_df.iloc[topk_indices][\"doc_id\"].tolist()\n",
    "\n",
    "        # ì •ë‹µ ë¬¸ì„œê°€ top-kì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸\n",
    "        if gt_doc_id in topk_doc_ids:\n",
    "            hit_count += 1\n",
    "\n",
    "    recall_at_k = hit_count / len(qa_pairs)\n",
    "    print(f\"ğŸ“Œ Recall@{k}: {recall_at_k:.4f}\")\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Recall@K: 87599it [01:35, 914.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Recall@10: 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recall_dpr = compute_dpr_recall(\n",
    "    qa_pairs=qa_pairs,\n",
    "    corpus_df=corpus_df,\n",
    "    ctx_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_ctx_embeddings2.npy\",\n",
    "    q_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_q_embeddings2.npy\",\n",
    "    k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPR-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dprm_recall(\n",
    "    qa_pairs: pd.DataFrame,\n",
    "    corpus_df: pd.DataFrame,\n",
    "    ctx_emb_path: str,\n",
    "    q_emb_path: str,\n",
    "    k: int = 5,\n",
    "    aggregation: str = \"max\",  # or \"mean\"\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    ë¬¸ì¥ ë‹¨ìœ„ì˜ ë¬¸ì„œ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ DPR-m ë°©ì‹ì˜ Recall@k ê³„ì‚°.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (pd.DataFrame): ì§ˆë¬¸-ì •ë‹µ ìŒ (columns: ['question', 'answer', 'doc_id'])\n",
    "        corpus_df (pd.DataFrame): ë¬¸ì„œ ì§‘í•© (columns: ['doc_id', 'text'])\n",
    "        ctx_emb_path (str): ë¬¸ì¥ ë‹¨ìœ„ ë¬¸ì„œ ì„ë² ë”© ì €ì¥ ê²½ë¡œ (.npy, shape: [num_docs, num_sents, dim])\n",
    "        q_emb_path (str): ì§ˆë¬¸ ì„ë² ë”© ì €ì¥ ê²½ë¡œ (.npy, shape: [num_queries, dim])\n",
    "        k (int): Recall@k\n",
    "        aggregation (str): 'max' ë˜ëŠ” 'mean' ë°©ì‹ìœ¼ë¡œ ë¬¸ì„œ ìœ ì‚¬ë„ ì§‘ê³„\n",
    "        \n",
    "    Returns:\n",
    "        float: Recall@k\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ì„ë² ë”© ë¡œë“œ\n",
    "    ctx_embeddings = np.load(ctx_emb_path)     # shape: (num_docs, num_sents, dim)\n",
    "    q_embeddings = np.load(q_emb_path)         # shape: (num_queries, dim)\n",
    "\n",
    "    assert len(q_embeddings) == len(qa_pairs), \"â— ì§ˆë¬¸ ì„ë² ë”© ìˆ˜ì™€ QA ìŒ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    hit_count = 0\n",
    "\n",
    "    # 2. ê° ì§ˆë¬¸ì— ëŒ€í•´ ë¬¸ì„œë“¤ê³¼ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    for idx, row in tqdm(qa_pairs.iterrows(), total=len(qa_pairs), desc=\"Evaluating DPR-m Recall@K\"):\n",
    "        gt_doc_id = row[\"doc_id\"]\n",
    "        q_emb = q_embeddings[idx]                     # shape: (dim,)\n",
    "        \n",
    "        # ë¬¸ì„œë³„ ë¬¸ì¥ë“¤ê³¼ ìœ ì‚¬ë„ â†’ shape: (num_docs, num_sents)\n",
    "        dot_products = np.einsum(\"ijk,k->ij\", ctx_embeddings, q_emb)  # íš¨ìœ¨ì ì¸ ë²¡í„° ì—°ì‚°\n",
    "\n",
    "        # ë¬¸ì„œ ë‹¨ìœ„ ìœ ì‚¬ë„ ì§‘ê³„\n",
    "        if aggregation == \"max\":\n",
    "            scores = np.max(dot_products, axis=1)     # (num_docs,)\n",
    "        elif aggregation == \"mean\":\n",
    "            scores = np.mean(dot_products, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"aggregationì€ 'max' ë˜ëŠ” 'mean'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # top-k ë¬¸ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "        topk_indices = np.argsort(scores)[::-1][:k]\n",
    "        topk_doc_ids = corpus_df.iloc[topk_indices][\"doc_id\"].tolist()\n",
    "\n",
    "        # ì •ë‹µ í¬í•¨ ì—¬ë¶€ í™•ì¸\n",
    "        if gt_doc_id in topk_doc_ids:\n",
    "            hit_count += 1\n",
    "\n",
    "    recall_at_k = hit_count / len(qa_pairs)\n",
    "    print(f\"ğŸ“Œ DPR-m Recall@{k} ({aggregation} aggregation): {recall_at_k:.4f}\")\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dprm_recall(\n",
    "    qa_pairs=qa_pairs,\n",
    "    corpus_df=corpus_df,\n",
    "    ctx_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_m_ctx_embeddings2.npy\",\n",
    "    q_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_q_embeddings2.npy\",\n",
    "    k=5,\n",
    "    aggregation=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hybrid (bm25 + DPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hybrid_recall(\n",
    "    qa_pairs: pd.DataFrame,\n",
    "    corpus_df: pd.DataFrame,\n",
    "    ctx_emb_path: str,\n",
    "    q_emb_path: str,\n",
    "    bm25_top_n: int = 100,\n",
    "    k: int = 5\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    BM25 + DPR hybrid retrieval ê¸°ë°˜ Recall@k ê³„ì‚°\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (pd.DataFrame): ì§ˆë¬¸-ì •ë‹µ ìŒ (columns: ['question', 'answer', 'doc_id'])\n",
    "        corpus_df (pd.DataFrame): ë¬¸ì„œ ì§‘í•© (columns: ['doc_id', 'text'])\n",
    "        ctx_emb_path (str): DPR ë¬¸ì„œ ì„ë² ë”© ê²½ë¡œ (.npy, shape: [num_docs, dim])\n",
    "        q_emb_path (str): DPR ì§ˆë¬¸ ì„ë² ë”© ê²½ë¡œ (.npy, shape: [num_queries, dim])\n",
    "        bm25_top_n (int): BM25ë¡œ ë¨¼ì € ì„ íƒí•  í›„ë³´ ë¬¸ì„œ ê°œìˆ˜\n",
    "        k (int): ìµœì¢… DPR top-kì—ì„œ ì •ë‹µ í¬í•¨ ì—¬ë¶€ í‰ê°€\n",
    "\n",
    "    Returns:\n",
    "        float: Recall@k\n",
    "    \"\"\"\n",
    "    # 1. ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    ctx_embeddings = np.load(ctx_emb_path)     # shape: (num_docs, dim)\n",
    "    q_embeddings = np.load(q_emb_path)         # shape: (num_queries, dim)\n",
    "    assert len(q_embeddings) == len(qa_pairs), \"â— ì§ˆë¬¸ ì„ë² ë”© ìˆ˜ì™€ QA ìŒ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # 2. BM25 ì¸ë±ìŠ¤ êµ¬ì„±\n",
    "    tokenized_corpus = [doc.split() for doc in corpus_df[\"text\"]]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    hit_count = 0\n",
    "\n",
    "    # 3. ê° ì§ˆë¬¸ì— ëŒ€í•´ hybrid retrieval ìˆ˜í–‰\n",
    "    for idx, row in tqdm(qa_pairs.iterrows(), total=len(qa_pairs), desc=\"Evaluating Hybrid Recall@K\"):\n",
    "        question = row[\"question\"]\n",
    "        gt_doc_id = row[\"doc_id\"]\n",
    "        q_emb = q_embeddings[idx]  # (dim,)\n",
    "\n",
    "        # (1) BM25 í›„ë³´ ì¶”ì¶œ\n",
    "        tokenized_query = question.split()\n",
    "        bm25_scores = bm25.get_scores(tokenized_query)\n",
    "        bm25_top_indices = np.argsort(bm25_scores)[::-1][:bm25_top_n]\n",
    "\n",
    "        # (2) DPR ìœ ì‚¬ë„ ê³„ì‚° (bm25 í›„ë³´ì— í•œí•´)\n",
    "        candidate_ctx_embs = ctx_embeddings[bm25_top_indices]  # (bm25_top_n, dim)\n",
    "        dpr_scores = np.dot(candidate_ctx_embs, q_emb)         # (bm25_top_n,)\n",
    "\n",
    "        # (3) DPR ê¸°ë°˜ top-k ë¬¸ì„œ ì„ íƒ\n",
    "        topk_local_indices = np.argsort(dpr_scores)[::-1][:k]\n",
    "        topk_doc_indices = [bm25_top_indices[i] for i in topk_local_indices]\n",
    "        topk_doc_ids = corpus_df.iloc[topk_doc_indices][\"doc_id\"].tolist()\n",
    "\n",
    "        # (4) ì •ë‹µ í¬í•¨ ì—¬ë¶€ í™•ì¸\n",
    "        if gt_doc_id in topk_doc_ids:\n",
    "            hit_count += 1\n",
    "\n",
    "    recall_at_k = hit_count / len(qa_pairs)\n",
    "    print(f\"ğŸ“Œ Hybrid Recall@{k} (BM25 top-{bm25_top_n} + DPR top-{k}): {recall_at_k:.4f}\")\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_hybrid_recall(\n",
    "    qa_pairs=qa_pairs,\n",
    "    corpus_df=corpus_df,\n",
    "    ctx_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_ctx_embeddings2.npy\",\n",
    "    q_emb_path=\"/mnt/aix7101/jeong/aix_project/dpr_q_embeddings2.npy\",\n",
    "    bm25_top_n=20,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Retrieval êµ¬ì„± ìš”ì†Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- keyword extraction function\n",
    "# 1. rule-based \n",
    "\n",
    "# 2. keyBERT\n",
    "\n",
    "# 3. Hybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- custom checking code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
